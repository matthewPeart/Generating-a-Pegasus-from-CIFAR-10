{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pegasus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0XeNJMELfIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "!pip install 'livelossplot==0.3.0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N22Uz-kLiZW",
        "colab_type": "text"
      },
      "source": [
        "**Main imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK1Jl7nkLnPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "from livelossplot import PlotLosses\n",
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run1dh_hM0oO",
        "colab_type": "text"
      },
      "source": [
        "**Import dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK383zeDM4Ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to make getting another batch of data easier.\n",
        "def cycle(iterable):\n",
        "    while True:\n",
        "        for x in iterable:\n",
        "            yield x\n",
        "            \n",
        "# Sampling function to select specific class labels.\n",
        "def get_samples(dataset, class_labels):\n",
        "  \n",
        "  indices = []\n",
        "  \n",
        "  for i in range(len(dataset)):\n",
        "    if dataset[i][1] in class_labels:\n",
        "      indices.append(i)\n",
        "      \n",
        "  return indices\n",
        "\n",
        "class_names = ['airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Use both the traning and test sets for learning.\n",
        "dataset = ConcatDataset([\n",
        "    torchvision.datasets.CIFAR10('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ])),\n",
        "    torchvision.datasets.CIFAR10('data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))])\n",
        "\n",
        "# Select only bird and horse images.\n",
        "image_ind = get_samples(dataset, [2, 7])\n",
        "\n",
        "# Wrap the dataset into a loader.\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                             shuffle=False, batch_size=16, drop_last=True,\n",
        "                                             sampler=torch.utils.data.sampler.SubsetRandomSampler(image_ind))\n",
        "\n",
        "dataset_iterator = iter(cycle(dataset_loader))\n",
        "\n",
        "print(f'> Size of dataset {len(dataset_loader.dataset)}')\n",
        "print(f'> Size of samples {len(image_ind)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-FdW5HnimG2",
        "colab_type": "text"
      },
      "source": [
        "**View some of the test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtJs-qxHRLXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(dataset_loader.dataset[image_ind[i]][0].permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[dataset_loader.dataset[image_ind[i]][1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnjh12UbNFpV",
        "colab_type": "text"
      },
      "source": [
        "**Define a simple model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGbLY6X-NH4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the components of the deep convolutional generative adversarial network (DCGAN).\n",
        "\n",
        "# Define the Generator network.\n",
        "class GANGen(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(GANGen, self).__init__()\n",
        "    \n",
        "    # Define a linear layer (32//4 because we upsample twice).\n",
        "    self.seq = nn.Linear(100, 128*(32//4)**2)\n",
        "    \n",
        "    # Batch normalisation one.\n",
        "    self.bn_one = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
        "    \n",
        "    # Upsample one.\n",
        "    self.up_one = nn.Upsample(scale_factor=2)\n",
        "    \n",
        "    # First convolutional layer.\n",
        "    self.conv_one = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "    \n",
        "    # Batch normalisation two.\n",
        "    self.bn_two = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
        "    \n",
        "    # Upsample two.\n",
        "    self.up_two = nn.Upsample(scale_factor=2)\n",
        "    \n",
        "    # Second convolutional layer.\n",
        "    self.conv_two = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
        "    \n",
        "    # Batch normalisation three.\n",
        "    self.bn_three = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
        "    \n",
        "    # Third convolutional layer.\n",
        "    self.conv_three = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
        "    \n",
        "    # Pass through a hyperbolic tangent.\n",
        "    self.tanh = nn.Tanh()\n",
        "    \n",
        "    # Define the activation function used throughout the network.\n",
        "    self.activ = nn.LeakyReLU(0.1, inplace=True)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    # Complete a forward pass.\n",
        "    x = self.seq(x)\n",
        "    \n",
        "    # Dimension after the linear layer.\n",
        "    x = x.view(x.shape[0], 128, (32//4), (32//4))\n",
        "    \n",
        "    # Block one.\n",
        "    x = self.bn_one(x)\n",
        "    x = self.up_one(x)\n",
        "    x = self.conv_one(x)\n",
        "    \n",
        "    # Block two.\n",
        "    x = self.bn_two(x)\n",
        "    x = self.activ(x)\n",
        "    x = self.up_two(x)\n",
        "    x = self.conv_two(x)\n",
        "    \n",
        "    # Block three.\n",
        "    x = self.bn_three(x)\n",
        "    x = self.activ(x)\n",
        "    x = self.conv_three(x)\n",
        "    \n",
        "    x = self.tanh(x)\n",
        "    \n",
        "    return x\n",
        "    \n",
        "    \n",
        "# Define the Discriminator network.\n",
        "class GANDis(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(GANDis, self).__init__()\n",
        "    \n",
        "    # First convolutional layer.\n",
        "    self.conv_one = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1)\n",
        "    \n",
        "    # Second convolutional layer.\n",
        "    self.conv_two = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
        "    \n",
        "    # Batch normalisation two.\n",
        "    self.bn_two = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
        "    \n",
        "    # Third convolutional layer.\n",
        "    self.conv_three = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
        "    \n",
        "    # Batch normalisation three.\n",
        "    self.bn_three = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
        "    \n",
        "    # Define a sequential layer (outputs between 0 - 1).\n",
        "    self.seq = nn.Sequential(nn.Linear(64*4*4, 1), nn.Sigmoid())\n",
        "    \n",
        "    # Define the dropout function.\n",
        "    self.drop = nn.Dropout2d(0.2)\n",
        "    \n",
        "    # Define the activation function.\n",
        "    self.activ = nn.LeakyReLU(0.1, inplace=True)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    # Complete a forward pass.\n",
        "    x = self.conv_one(x)\n",
        "    x = self.activ(x)\n",
        "    x = self.drop(x)\n",
        "    \n",
        "    x = self.conv_two(x)\n",
        "    x = self.activ(x)\n",
        "    x = self.drop(x)\n",
        "    x = self.bn_two(x)\n",
        "    \n",
        "    x = self.conv_three(x)\n",
        "    x = self.activ(x)\n",
        "    x = self.drop(x)\n",
        "    x = self.bn_three(x)\n",
        "    \n",
        "    # Reshape the data.\n",
        "    x = x.view(-1, 64*4*4)\n",
        "    \n",
        "    return self.seq(x)\n",
        "    \n",
        "\n",
        "# Create the networks.\n",
        "generator = GANGen().to(device)\n",
        "discriminator = GANDis().to(device)    \n",
        "    \n",
        "# Define the loss function.\n",
        "loss = torch.nn.BCELoss()\n",
        "\n",
        "# Initialise the optimisers.\n",
        "opt_g = torch.optim.Adam(generator.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
        "opt_d = torch.optim.Adam(discriminator.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
        "\n",
        "print(f'> Number of generator parameters {len(torch.nn.utils.parameters_to_vector(generator.parameters()))}')\n",
        "print(f'> Number of discriminator parameters {len(torch.nn.utils.parameters_to_vector(discriminator.parameters()))}')\n",
        "\n",
        "num_epoch = 1000000\n",
        "liveplot = PlotLosses()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1UBl0PJjY-f",
        "colab_type": "text"
      },
      "source": [
        "**Main training loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb5909Y8D_zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define ground truth.\n",
        "ones = torch.FloatTensor(16, 1).fill_(1.0)\n",
        "zeros = torch.FloatTensor(16, 1).fill_(0.0)\n",
        "valid = Variable(ones, requires_grad=False)\n",
        "fake = Variable(zeros, requires_grad=False)\n",
        "valid, fake = valid.to(device), fake.to(device)\n",
        "\n",
        "# training loop.\n",
        "for epoch in range(num_epoch):\n",
        "  \n",
        "  # arrays for metrics\n",
        "  generator_loss_arr = np.zeros(0)\n",
        "  discriminator_loss_arr = np.zeros(0) \n",
        "  \n",
        "  # Loop through the images of the data loader.\n",
        "  for i, images in enumerate(dataset_loader):\n",
        "\n",
        "    images = images[0].to(device)\n",
        "    real_imgs = Variable(images.type(Tensor))\n",
        "\n",
        "    # TRAIN THE GENERATOR NETWORK # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    opt_g.zero_grad()\n",
        "\n",
        "    # Generate 16 fake images from random noise.\n",
        "    fake_images = generator(Variable(Tensor(np.random.normal(0, 1, (16, 100)))))\n",
        "\n",
        "    # Measure loss on on how well the generator fools the discriminator.\n",
        "    loss_g = loss(discriminator(fake_images), valid)\n",
        "\n",
        "    # Back-propagate the error.\n",
        "    loss_g.backward()\n",
        "\n",
        "    # Step the optimiser.\n",
        "    opt_g.step()\n",
        "\n",
        "    # TRAIN THE DISCRIMINATOR NETWORK # ~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    opt_d.zero_grad()\n",
        "\n",
        "    # Calculate loss on some fake and some real images.\n",
        "    loss_f = loss(discriminator(fake_images.detach()), fake)\n",
        "    loss_r = loss(discriminator(real_imgs), valid)\n",
        "    loss_d = 0.5 * (loss_f + loss_r)\n",
        "\n",
        "    # Back-propagate the error.\n",
        "    loss_d.backward()\n",
        "\n",
        "    # Step the optimiser.\n",
        "    opt_d.step()\n",
        "\n",
        "    # Udate the generator loss array.\n",
        "    generator_loss_arr = np.append(generator_loss_arr, loss_g.cpu().data)\n",
        "\n",
        "    # Update the discriminator loss array.\n",
        "    discriminator_loss_arr = np.append(discriminator_loss_arr, loss_d.cpu().data)\n",
        "    \n",
        "    # Show the images generated after every epoch.\n",
        "    if i == 0:\n",
        "      \n",
        "      # Loop through each fake image and display it.\n",
        "      plt.figure(figsize=(8,8))\n",
        "      for t in range(16):\n",
        "        plt.subplot(4,4,t+1)\n",
        "        plt.grid(False)\n",
        "        plt.imshow(fake_images[t].cpu().data.numpy().transpose((1,2,0)))\n",
        "\n",
        "  # NOTE: live plot library has dumb naming forcing our 'test' to be called 'validation'\n",
        "  liveplot.update({\n",
        "      'Generator Loss': generator_loss_arr.mean(),\n",
        "      'Discriminator Loss': discriminator_loss_arr.mean() \n",
        "  })\n",
        "  liveplot.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTFqiEHzMOVw",
        "colab_type": "text"
      },
      "source": [
        "**Generate a Pegasus by interpolating  the joint latent space encodings of a horse and a bird**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqv3w6b0nKbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Search the latent space of the GAN for an image of a pegasus.\n",
        "\n",
        "# Generate 16 random images from noise.\n",
        "noise = Variable(Tensor(np.random.normal(0, 1, (16, 100))))\n",
        "fake_images = generator(noise)\n",
        "\n",
        "# Loop through each fake image and display it.\n",
        "plt.figure(figsize=(8,8))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(fake_images[i].cpu().data.numpy().transpose((1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oek8E0uRC7aQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "\n",
        "matplotlib.image.imsave('data/pegasus.png', fake_images[3].cpu().data.numpy().transpose((1,2,0)))\n",
        "\n",
        "from google.colab import files\n",
        "files.download( \"data/pegasus.png\" ) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}